{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"source":["!pip install torchdata"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-04-18T06:45:32.952055Z","iopub.execute_input":"2023-04-18T06:45:32.953000Z","iopub.status.idle":"2023-04-18T06:47:29.557848Z","shell.execute_reply.started":"2023-04-18T06:45:32.952946Z","shell.execute_reply":"2023-04-18T06:47:29.556625Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import torch\r\n","import torch.nn as nn\r\n","\r\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n","\r\n","import torchtext.transforms as T\r\n","from torch.hub import load_state_dict_from_url\r\n","\r\n","padding_idx = 1\r\n","bos_idx = 0\r\n","eos_idx = 2\r\n","max_seq_len = 256\r\n","vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\r\n","spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\r\n","#spm_model_path = r\"https://huggingface.co/IDEA-CCNL/Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece/resolve/main/spm.model\"\r\n","\r\n","text_transform = T.Sequential(\r\n","    T.SentencePieceTokenizer(spm_model_path),\r\n","    T.VocabTransform(load_state_dict_from_url(vocab_path)),\r\n","    T.Truncate(max_seq_len - 2),\r\n","    T.AddToken(token=bos_idx, begin=True),\r\n","    T.AddToken(token=eos_idx, begin=False),\r\n",")\r\n","\r\n","from torchdata.datapipes.iter import IterableWrapper\r\n","train_datapipe = IterableWrapper([\"/kaggle/input/intent-recog/train.csv\"])\r\n","train_datapipe = train_datapipe.open_files(encoding=\"utf-8\").parse_csv()\r\n","train_datapipe = train_datapipe.shuffle().sharding_filter()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-04-18T06:47:29.561895Z","iopub.execute_input":"2023-04-18T06:47:29.562226Z","iopub.status.idle":"2023-04-18T06:47:31.951628Z","shell.execute_reply.started":"2023-04-18T06:47:29.562190Z","shell.execute_reply":"2023-04-18T06:47:31.950607Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["test_datapipe = IterableWrapper([\"/kaggle/input/intent-recog/test.csv\"])\r\n","test_datapipe = test_datapipe.open_files(encoding=\"utf-8\").parse_csv()\r\n","test_datapipe = test_datapipe.shuffle().sharding_filter()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-04-18T06:47:31.953123Z","iopub.execute_input":"2023-04-18T06:47:31.953918Z","iopub.status.idle":"2023-04-18T06:47:31.959853Z","shell.execute_reply.started":"2023-04-18T06:47:31.953883Z","shell.execute_reply":"2023-04-18T06:47:31.958747Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["batch_size = 128\r\n","\r\n","def batch_transform(x):\r\n","    return text_transform(x[0]), int(x[1])-1\r\n","\r\n","train_datapipe = train_datapipe.map(batch_transform)\r\n","train_datapipe = train_datapipe.batch(batch_size)\r\n","train_datapipe = train_datapipe.rows2columnar([\"token_ids\", \"target\"])\r\n","\r\n","\r\n","from torch.utils.data import DataLoader\r\n","train_dataloader = DataLoader(train_datapipe, batch_size=None)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-04-18T06:47:31.962647Z","iopub.execute_input":"2023-04-18T06:47:31.963480Z","iopub.status.idle":"2023-04-18T06:47:31.972748Z","shell.execute_reply.started":"2023-04-18T06:47:31.963440Z","shell.execute_reply":"2023-04-18T06:47:31.971820Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["test_datapipe = test_datapipe.map(batch_transform)\r\n","test_datapipe = test_datapipe.batch(batch_size)\r\n","test_datapipe = test_datapipe.rows2columnar([\"token_ids\", \"target\"])\r\n","test_dataloader = DataLoader(test_datapipe, batch_size=None)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-04-18T06:47:31.974148Z","iopub.execute_input":"2023-04-18T06:47:31.974669Z","iopub.status.idle":"2023-04-18T06:47:31.984159Z","shell.execute_reply.started":"2023-04-18T06:47:31.974629Z","shell.execute_reply":"2023-04-18T06:47:31.983028Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["num_classes = 14\r\n","input_dim = 768\r\n","\r\n","from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\r\n","\r\n","classifier_head = RobertaClassificationHead(num_classes=num_classes, input_dim=input_dim)\r\n","model = XLMR_BASE_ENCODER.get_model(head=classifier_head)\r\n","model.to(DEVICE)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-04-18T06:47:31.985428Z","iopub.execute_input":"2023-04-18T06:47:31.985866Z","iopub.status.idle":"2023-04-18T06:47:43.969458Z","shell.execute_reply.started":"2023-04-18T06:47:31.985826Z","shell.execute_reply":"2023-04-18T06:47:43.968269Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import torchtext.functional as F\r\n","from torch.optim import AdamW\r\n","\r\n","learning_rate = 1e-5\r\n","optim = AdamW(model.parameters(), lr=learning_rate)\r\n","criteria = nn.CrossEntropyLoss()\r\n","\r\n","\r\n","def train_step(input, target):\r\n","    output = model(input)\r\n","    loss = criteria(output, target)\r\n","    optim.zero_grad()\r\n","    loss.backward()\r\n","    optim.step()\r\n","\r\n","\r\n","def eval_step(input, target):\r\n","    output = model(input)\r\n","    loss = criteria(output, target).item()\r\n","    acc = (output.argmax(1) == target).type(torch.float).mean()\r\n","    print(acc)\r\n","    return float(loss), acc\r\n","\r\n","def evaluate():\r\n","    model.eval()\r\n","    total_loss = 0\r\n","    correct_predictions = 0\r\n","    total_predictions = 0\r\n","    counter = 0\r\n","    with torch.no_grad():\r\n","        for batch in test_dataloader:\r\n","            input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(DEVICE)\r\n","            target = torch.tensor(batch[\"target\"]).to(DEVICE)\r\n","            loss, predictions = eval_step(input, target)\r\n","            total_loss += loss\r\n","            correct_predictions += predictions\r\n","            \r\n","            total_predictions += 1\r\n","            counter += 1\r\n","\r\n","    return total_loss / counter, correct_predictions / total_predictions\r\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-04-18T06:47:43.970946Z","iopub.execute_input":"2023-04-18T06:47:43.971596Z","iopub.status.idle":"2023-04-18T06:47:43.984060Z","shell.execute_reply.started":"2023-04-18T06:47:43.971556Z","shell.execute_reply":"2023-04-18T06:47:43.982724Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["num_epochs = 20\r\n","\r\n","for e in range(num_epochs):\r\n","    for batch in train_dataloader:\r\n","        input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(DEVICE)\r\n","        target = torch.tensor(batch[\"target\"]).to(DEVICE)\r\n","        train_step(input, target)\r\n","    loss, accuracy = evaluate()\r\n","    print(\"TEST Epoch = [{}], loss = [{}], accuracy = [{}]\".format(e, loss, accuracy))\r\n","torch.save(model, \"./model.pt\")"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-04-18T06:47:43.985565Z","iopub.execute_input":"2023-04-18T06:47:43.986615Z","iopub.status.idle":"2023-04-18T06:53:36.703771Z","shell.execute_reply.started":"2023-04-18T06:47:43.986507Z","shell.execute_reply":"2023-04-18T06:53:36.702558Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["!ls"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2023-04-18T06:54:54.971194Z","iopub.execute_input":"2023-04-18T06:54:54.971847Z","iopub.status.idle":"2023-04-18T06:54:55.970779Z","shell.execute_reply.started":"2023-04-18T06:54:54.971791Z","shell.execute_reply":"2023-04-18T06:54:55.969549Z"},"trusted":true}}]}