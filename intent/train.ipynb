{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "#DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "DEVICE = 'cpu'\r\n",
    "\r\n",
    "import torchtext.transforms as T\r\n",
    "from torch.hub import load_state_dict_from_url\r\n",
    "\r\n",
    "padding_idx = 1\r\n",
    "bos_idx = 0\r\n",
    "eos_idx = 2\r\n",
    "max_seq_len = 256\r\n",
    "vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\r\n",
    "#spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\r\n",
    "spm_model_path = r\"https://huggingface.co/IDEA-CCNL/Erlangshen-DeBERTa-v2-186M-Chinese-SentencePiece/resolve/main/spm.model\"\r\n",
    "\r\n",
    "text_transform = T.Sequential(\r\n",
    "    T.SentencePieceTokenizer(spm_model_path),\r\n",
    "    T.VocabTransform(load_state_dict_from_url(vocab_path)),\r\n",
    "    T.Truncate(max_seq_len - 2),\r\n",
    "    T.AddToken(token=bos_idx, begin=True),\r\n",
    "    T.AddToken(token=eos_idx, begin=False),\r\n",
    ")\r\n",
    "from torchdata.datapipes.iter import IterableWrapper\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "batch_size = 128\r\n",
    "\r\n",
    "def batch_transform(x):\r\n",
    "    return text_transform(x[0]), int(x[1])-1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torchdata.datapipes.iter import IterableWrapper\r\n",
    "train_datapipe = IterableWrapper([\"./data/train.csv\"])\r\n",
    "train_datapipe = train_datapipe.open_files(encoding=\"utf-8\").parse_csv()\r\n",
    "train_datapipe = train_datapipe.shuffle().sharding_filter()\r\n",
    "list(train_datapipe)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "test_datapipe = IterableWrapper([\"./data/test.csv\"])\r\n",
    "test_datapipe = test_datapipe.open_files(encoding=\"utf-8\").parse_csv()\r\n",
    "test_datapipe = test_datapipe.shuffle().sharding_filter()\r\n",
    "list(test_datapipe)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['能简单介绍下site', '7'],\n",
       " ['请问site在哪', '1'],\n",
       " ['讲讲city和locale的关系', '2'],\n",
       " ['site感觉很有名，能介绍一下吗', '7'],\n",
       " ['帮我查下site的官网', '6'],\n",
       " ['site这块有啥商店吗', '9'],\n",
       " ['你好，请问locale是哪个州的', '1'],\n",
       " ['city下面有哪几个区', '10'],\n",
       " ['我该怎么去site', '3'],\n",
       " ['site还有site之间有啥关系', '2'],\n",
       " ['site有官方网站没', '6'],\n",
       " ['region和locale间有啥关系', '2'],\n",
       " ['饿死我了，site附近有什么吃的吗', '8'],\n",
       " ['请问site有联系电话没有', '5'],\n",
       " ['locale的地址是啥', '1'],\n",
       " ['state与country间有关系', '2'],\n",
       " ['site附近还有什么好地方', '11'],\n",
       " ['请问locale在哪里呀', '1'],\n",
       " ['site这块有没有什么购物的地方', '9'],\n",
       " ['请讲讲state还有country的联系', '2'],\n",
       " ['我有点饿了，locale这块有啥吃的吗', '8'],\n",
       " ['locale里有没有值得逛逛的地方', '10'],\n",
       " ['讲讲country和site间有啥关系', '2'],\n",
       " ['site有什么介绍没有', '7'],\n",
       " ['这个city是state的什么', '2'],\n",
       " ['city是哪个国的', '1'],\n",
       " ['饿了，推荐点locale这里的饭店', '8'],\n",
       " ['你好，请问怎么到locale', '3'],\n",
       " ['site有啥联系方式没', '4'],\n",
       " ['site附近有什么好地方值得一去', '11']]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_datapipe = train_datapipe.map(batch_transform)\r\n",
    "train_datapipe = train_datapipe.batch(batch_size)\r\n",
    "train_datapipe = train_datapipe.rows2columnar([\"token_ids\", \"target\"])\r\n",
    "\r\n",
    "train_dataloader = DataLoader(train_datapipe, batch_size=None)\r\n",
    "list(train_datapipe)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "test_datapipe = test_datapipe.map(batch_transform)\r\n",
    "test_datapipe = test_datapipe.batch(batch_size)\r\n",
    "test_datapipe = test_datapipe.rows2columnar([\"token_ids\", \"target\"])\r\n",
    "test_dataloader = DataLoader(test_datapipe, batch_size=None)\r\n",
    "list(test_datapipe)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[defaultdict(list,\n",
       "             {'token_ids': [[0, 91, 1486, 9679, 11090, 3, 88812, 11233, 2],\n",
       "               [0, 7001, 1935, 2008, 87154, 24417, 3, 16076, 2],\n",
       "               [0, 3, 55043, 1935, 164691, 41978, 2],\n",
       "               [0, 3, 4, 200757, 55043, 1935, 3, 3, 2],\n",
       "               [0, 91, 1486, 465, 220213, 7064, 2],\n",
       "               [0, 3, 60089, 354, 61340, 43, 6711, 2],\n",
       "               [0, 3, 11090, 465, 3, 3029, 2],\n",
       "               [0, 11341, 1189, 238, 3, 1294, 11158, 3, 2],\n",
       "               [0, 3, 3, 61340, 9679, 238, 3, 1294, 3, 2],\n",
       "               [0, 3, 37085, 3, 11090, 2],\n",
       "               [0, 6, 3, 4, 49732, 2391, 55043, 1935, 151521, 3, 2],\n",
       "               [0, 6, 3, 60089, 264, 55043, 1935, 86282, 2],\n",
       "               [0, 3, 11090, 3, 2],\n",
       "               [0, 26349, 3, 3, 2],\n",
       "               [0, 13129, 35679, 3, 4, 55043, 1935, 3, 3, 90146, 9131, 2],\n",
       "               [0, 6, 3, 238, 3, 1294, 264, 11090, 11158, 3, 11233, 2],\n",
       "               [0, 91, 1486, 3, 3, 58934, 9131, 2],\n",
       "               [0, 91, 1486, 34643, 3, 10491, 3, 1677, 2],\n",
       "               [0, 91, 1486, 3, 3, 7064, 2],\n",
       "               [0, 6835, 1830, 264, 55043, 1935, 11158, 3, 11233, 2],\n",
       "               [0, 91, 1486, 34643, 3, 1322, 10491, 2],\n",
       "               [0, 3, 4, 200757, 12082, 789, 55043, 1935, 2],\n",
       "               [0, 91, 1486, 47097, 17866, 3029, 2],\n",
       "               [0, 6, 3, 3, 4, 11090, 34643, 47097, 90146, 9131, 2],\n",
       "               [0, 91, 1486, 26379, 51637, 1795, 4, 1580, 217645, 9131, 2],\n",
       "               [0, 13129, 3, 1677, 11090, 2],\n",
       "               [0, 91, 1486, 3, 3, 103093, 16076, 2],\n",
       "               [0, 6, 191351, 9258, 1130, 11090, 43, 52583, 2],\n",
       "               [0, 7001, 1935, 3, 3, 2],\n",
       "               [0, 26349, 25735, 3, 28138, 3624, 2]],\n",
       "              'target': [1,\n",
       "               9,\n",
       "               0,\n",
       "               0,\n",
       "               5,\n",
       "               1,\n",
       "               4,\n",
       "               1,\n",
       "               1,\n",
       "               6,\n",
       "               7,\n",
       "               1,\n",
       "               0,\n",
       "               0,\n",
       "               7,\n",
       "               1,\n",
       "               8,\n",
       "               10,\n",
       "               3,\n",
       "               1,\n",
       "               10,\n",
       "               2,\n",
       "               6,\n",
       "               7,\n",
       "               6,\n",
       "               2,\n",
       "               8,\n",
       "               5,\n",
       "               0,\n",
       "               9]})]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = torch.load(\"D:\\\\projects\\\\python\\\\test\\\\src\\\\intent\\\\model.pt\")\r\n",
    "model.to(DEVICE)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (encoder): RobertaEncoder(\n",
       "    (transformer): TransformerEncoder(\n",
       "      (token_embedding): Embedding(250002, 768, padding_idx=1)\n",
       "      (layers): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (positional_embedding): PositionalEmbedding(\n",
       "        (embedding): Embedding(514, 768, padding_idx=1)\n",
       "      )\n",
       "      (embedding_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (head): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=11, bias=True)\n",
       "    (activation_fn): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import torchtext.functional as F\r\n",
    "\r\n",
    "def eval_step(input, target):\r\n",
    "    output = model(input)\r\n",
    "    return (output.argmax(1) == target).type(torch.float).mean().item()\r\n",
    "\r\n",
    "def evaluate():\r\n",
    "    model.eval()\r\n",
    "    correct_predictions = 0\r\n",
    "    total_predictions = 0\r\n",
    "    counter = 0\r\n",
    "    with torch.no_grad():\r\n",
    "        for batch in test_dataloader:\r\n",
    "            input = F.to_tensor(batch[\"token_ids\"], padding_value=padding_idx).to(DEVICE)\r\n",
    "            print(input)\r\n",
    "            target = torch.tensor(batch[\"target\"]).to(DEVICE)\r\n",
    "            predictions = eval_step(input, target)\r\n",
    "            correct_predictions += predictions\r\n",
    "\r\n",
    "            total_predictions += 1\r\n",
    "            counter += 1\r\n",
    "\r\n",
    "    return correct_predictions / total_predictions\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "accuracy = evaluate()\r\n",
    "print(\"accuracy = [{}]\".format(accuracy))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[     0,     91,   1486,      3,      3,  58934,   9131,      2,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,     91,   1486,   9679,  11090,      3,  88812,  11233,      2,\n",
      "              1,      1,      1],\n",
      "        [     0,     91,   1486,  34643,      3,  10491,      3,   1677,      2,\n",
      "              1,      1,      1],\n",
      "        [     0,      3,  55043,   1935, 164691,  41978,      2,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,      3,  11090,    465,      3,   3029,      2,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,      3,      4, 200757,  12082,    789,  55043,   1935,      2,\n",
      "              1,      1,      1],\n",
      "        [     0,      6,      3,      3,      4,  11090,  34643,  47097,  90146,\n",
      "           9131,      2,      1],\n",
      "        [     0,  26349,  25735,      3,  28138,   3624,      2,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,     91,   1486,      3,      3,   7064,      2,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,   7001,   1935,      3,      3,      2,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,     91,   1486,  47097,  17866,   3029,      2,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,      6, 191351,   9258,   1130,  11090,     43,  52583,      2,\n",
      "              1,      1,      1],\n",
      "        [     0,      3,  37085,      3,  11090,      2,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,      3,      4, 200757,  55043,   1935,      3,      3,      2,\n",
      "              1,      1,      1],\n",
      "        [     0,  26349,      3,      3,      2,      1,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,      3,      3,  61340,   9679,    238,      3,   1294,      3,\n",
      "              2,      1,      1],\n",
      "        [     0,      3,  11090,      3,      2,      1,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,  13129,  35679,      3,      4,  55043,   1935,      3,      3,\n",
      "          90146,   9131,      2],\n",
      "        [     0,   7001,   1935,   2008,  87154,  24417,      3,  16076,      2,\n",
      "              1,      1,      1],\n",
      "        [     0,     91,   1486,    465, 220213,   7064,      2,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,   6835,   1830,    264,  55043,   1935,  11158,      3,  11233,\n",
      "              2,      1,      1],\n",
      "        [     0,      6,      3,    238,      3,   1294,    264,  11090,  11158,\n",
      "              3,  11233,      2],\n",
      "        [     0,      3,  60089,    354,  61340,     43,   6711,      2,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,     91,   1486,  34643,      3,   1322,  10491,      2,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,     91,   1486,      3,      3, 103093,  16076,      2,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,     91,   1486,  26379,  51637,   1795,      4,   1580, 217645,\n",
      "           9131,      2,      1],\n",
      "        [     0,      6,      3,  60089,    264,  55043,   1935,  86282,      2,\n",
      "              1,      1,      1],\n",
      "        [     0,  13129,      3,   1677,  11090,      2,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     0,  11341,   1189,    238,      3,   1294,  11158,      3,      2,\n",
      "              1,      1,      1],\n",
      "        [     0,      6,      3,      4,  49732,   2391,  55043,   1935, 151521,\n",
      "              3,      2,      1]])\n",
      "accuracy = [0.7333333492279053]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.10 64-bit ('test': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "interpreter": {
   "hash": "bba7c29ece2c7d8bf96e77a6dae39f3d0f34b1b1557f23b4711417acd9b9299c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}